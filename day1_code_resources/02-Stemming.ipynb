{"cells":[{"cell_type":"markdown","metadata":{"id":"5p1XpGSRhGu1"},"source":["# Stemming\n","Often when searching text for a certain keyword, it helps if the search returns variations of the word. For instance, searching for \"boat\" might also return \"boats\" and \"boating\". Here, \"boat\" would be the **stem** for [boat, boater, boating, boats].\n","\n","Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached. This works fairly well in most cases, but unfortunately English has many exceptions where a more sophisticated process is required. In fact, spaCy doesn't include a stemmer, opting instead to rely entirely on lemmatization. For those interested, there's some background on this decision [here](https://github.com/explosion/spaCy/issues/327). We discuss the virtues of *lemmatization* in the next section.\n","\n","Instead, we'll use another popular NLP tool called **nltk**, which stands for *Natural Language Toolkit*. For more information on nltk visit https://www.nltk.org/"]},{"cell_type":"markdown","metadata":{"id":"faeteTDihGu1"},"source":["## Porter Stemmer\n","\n","One of the most common - and effective - stemming tools is [*Porter's Algorithm*](https://tartarus.org/martin/PorterStemmer/) developed by Martin Porter in [1980](https://tartarus.org/martin/PorterStemmer/def.txt). The algorithm employs five phases of word reduction, each with its own set of mapping rules. In the first phase, simple suffix mapping rules are defined, such as:"]},{"cell_type":"markdown","metadata":{"id":"oS7_czGBhGu2"},"source":["![stemming1.png](../stemming1.png)"]},{"cell_type":"markdown","metadata":{"id":"idZKwqgIhGu2"},"source":["From a given set of stemming rules only one rule is applied, based on the longest suffix S1. Thus, `caresses` reduces to `caress` but not `cares`.\n","\n","More sophisticated phases consider the length/complexity of the word before applying a rule. For example:"]},{"cell_type":"markdown","metadata":{"id":"x6SRT8mmhGu2"},"source":["![stemming1.png](../stemming2.png)"]},{"cell_type":"markdown","metadata":{"id":"4_By9A-qhGu2"},"source":["Here `m>0` describes the \"measure\" of the stem, such that the rule is applied to all but the most basic stems."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QL-ek3kPhGu3"},"outputs":[],"source":["# Import the toolkit and the full Porter Stemmer library\n","import nltk\n","\n","from nltk.stem.porter import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ps_f0qvlhGu4"},"outputs":[],"source":["p_stemmer = PorterStemmer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2NUCmr_5hGu4"},"outputs":[],"source":["words = ['run','runner','running','ran','runs','easily','fairly']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtZIdAGhhGu4","outputId":"9c421549-4574-41ab-ceb0-29fd10dd080e"},"outputs":[{"name":"stdout","output_type":"stream","text":["run --> run\n","runner --> runner\n","running --> run\n","ran --> ran\n","runs --> run\n","easily --> easili\n","fairly --> fairli\n"]}],"source":["for word in words:\n","    print(word+' --> '+p_stemmer.stem(word))"]},{"cell_type":"markdown","metadata":{"id":"f5F_1Cd2hGu5"},"source":["<font color=green>Note how the stemmer recognizes \"runner\" as a noun, not a verb form or participle. Also, the adverbs \"easily\" and \"fairly\" are stemmed to the unusual root \"easili\" and \"fairli\"</font>\n","___"]},{"cell_type":"markdown","metadata":{"id":"i4DHn7NyhGu5"},"source":["## Snowball Stemmer\n","This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since **nltk** uses the name SnowballStemmer, we'll use it here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKGtDbKvhGu5"},"outputs":[],"source":["from nltk.stem.snowball import SnowballStemmer\n","\n","# The Snowball Stemmer requires that you pass a language parameter\n","s_stemmer = SnowballStemmer(language='english')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pc_q2yWBhGu5"},"outputs":[],"source":["words = ['run','runner','running','ran','runs','easily','fairly']\n","# words = ['generous','generation','generously','generate']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0R9Xf3CThGu5","outputId":"d3061f2d-01b1-4f76-bda9-971fee4e3a4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["run --> run\n","runner --> runner\n","running --> run\n","ran --> ran\n","runs --> run\n","easily --> easili\n","fairly --> fair\n"]}],"source":["for word in words:\n","    print(word+' --> '+s_stemmer.stem(word))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"PLZvKjVXhGu5"},"source":["<font color=green>In this case the stemmer performed the same as the Porter Stemmer, with the exception that it handled the stem of \"fairly\" more appropriately with \"fair\"</font>\n","___"]},{"cell_type":"markdown","metadata":{"id":"cgZSva9NhGu5"},"source":["## Try it yourself!\n","#### Pass in some of your own words and test each stemmer on them. Remember to pass them as strings!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tsfWk9zhGu5"},"outputs":[],"source":["words = ['consolingly']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJlIEvKqhGu5","outputId":"c2f0bff6-a428-4b2a-ef9a-5a8b0c2d52eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Porter Stemmer:\n","consolingly --> consolingli\n"]}],"source":["print('Porter Stemmer:')\n","for word in words:\n","    print(word+' --> '+p_stemmer.stem(word))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"duOdBMOuhGu6","outputId":"06c6d251-c8e5-4848-b020-577d10c61108"},"outputs":[{"name":"stdout","output_type":"stream","text":["Porter2 Stemmer:\n","consolingly --> consol\n"]}],"source":["print('Porter2 Stemmer:')\n","for word in words:\n","    print(word+' --> '+s_stemmer.stem(word))"]},{"cell_type":"markdown","metadata":{"id":"n_l3v88ohGu6"},"source":["___\n","Stemming has its drawbacks. If given the token `saw`, stemming might always return `saw`, whereas lemmatization would likely return either `see` or `saw` depending on whether the use of the token was as a verb or a noun. As an example, consider the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5yCDcS-hGu6","outputId":"2ebe2296-54db-402c-8a8e-155bd16a8e2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["I --> I\n","am --> am\n","meeting --> meet\n","him --> him\n","tomorrow --> tomorrow\n","at --> at\n","the --> the\n","meeting --> meet\n"]}],"source":["phrase = 'I am meeting him tomorrow at the meeting'\n","for word in phrase.split():\n","    print(word+' --> '+p_stemmer.stem(word))"]},{"cell_type":"markdown","metadata":{"id":"ezbea4ekhGu6"},"source":["Here the word \"meeting\" appears twice - once as a verb, and once as a noun, and yet the stemmer treats both equally."]},{"cell_type":"markdown","metadata":{"id":"3CygwRI6hGu6"},"source":["### Next up: Lemmatization"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}