{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZyUfbONmx_1"
      },
      "outputs": [],
      "source": [
        "import math, time, json, random, os, sys\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_VLQTzCoQfs",
        "outputId": "022e8896-fccd-4248-d53e-164e5a5c363a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "xNpJv02MoYt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed()"
      ],
      "metadata": {
        "id": "kND7rALDoxRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load Data FashionMNIST**"
      ],
      "metadata": {
        "id": "qewQHR1RpFuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_workers = 2"
      ],
      "metadata": {
        "id": "3InCBhC6oyK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo cơ chế chuẩn hoá ảnh đầu vào\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "UOX-AlAqpQj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku17ycfMph7r",
        "outputId": "46cd4dbf-791f-4b35-fdb7-427361418bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 192kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.54MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Chia data thành các batch - truyền vào DataLoader**"
      ],
      "metadata": {
        "id": "ngu1UDrTp9fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=num_workers, pin_memory=True)"
      ],
      "metadata": {
        "id": "wisZCMXIp30U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_dataset.classes\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vWsvqztqf6P",
        "outputId": "6c1b34ea-7cf3-4b36-ff54-9cd2d6c298fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expert**"
      ],
      "metadata": {
        "id": "9Ep1OxRGqytR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Mỗi \"expert\" trong kiến trúc MOE là một mô hình nhỏ, độc lập\n",
        "+ \"expert\" được thiết kế đơn giản như một lớp Feed Forward Neural Network\n",
        "+ Mỗi \"expert\" có khả năng xử lý input một cách chuyên biệt"
      ],
      "metadata": {
        "id": "Pf_dtAtUq02v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "X-uZZcg9qjQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Router**"
      ],
      "metadata": {
        "id": "iRBZpRwWr4Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Đây là phần quan trọng nhất, quyết định expert nào sẽ xử lý input\n",
        "+ Phần Router, sử dụng top-k routing (chọn k expert có phần trăm cao nhất), nhưng thêm noisy (nhiễu) để tránh vấn đề \"expert collapse\" - nơi một expert handle toàn bộ input, dẫn đến các expert khác không được huấn luyện\n",
        "+ Noise chỉ được thêm trong quá trình training để khuyến khích router sử dụng đa dạng các expert, nhưng trong quá trình inference (test) thì không thêm\n",
        "+ noisy_std là chỉ số cho phép điều chỉnh mức độ noise (nhiễu)"
      ],
      "metadata": {
        "id": "jbRj5UmAr559"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TopKRouter(nn.Module):\n",
        "    def __init__(self, in_dim, num_experts, noisy_std=1.0):\n",
        "        super().__init__()\n",
        "        self.w_g = nn.Linear(in_dim, num_experts) # Dùng để tính ra tỷ lệ phần trăm expert nào sẽ được sử dụng (gating logits)\n",
        "        self.noisy_std = noisy_std\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.w_g(x)\n",
        "        if self.training and self.noisy_std > 0:\n",
        "            noise = torch.randn_like(logits) * self.noisy_std\n",
        "            logits += noise\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Cx_xi3Xlr5HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sparse MOE**"
      ],
      "metadata": {
        "id": "0Tb_2r8Qvjko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseMOE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_experts=8, top_k=2, dropout=0.1, noisy_std=1.0):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "        self.router = TopKRouter(in_dim, num_experts, noisy_std=noisy_std)\n",
        "        self.experts = nn.ModuleList([Expert(in_dim, hidden_dim, dropout=dropout) for _ in range(num_experts)])\n",
        "        self.combine = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Tính logits [B, experts] - đại diện cho điểm số (scores) cho từng expert đối với mỗi sample trong batch\n",
        "        # Batch = 10, expert = 8\n",
        "        '''\n",
        "        [\n",
        "          [0.3, 0.1, 0.2, ..., 0.05],\n",
        "          [],\n",
        "          [],\n",
        "          [],\n",
        "          ...,\n",
        "          []\n",
        "        ]\n",
        "        '''\n",
        "        logits = self.router(x)\n",
        "        # Sử dụng torch.topk để lấy top-k giá trị lớn nhất (top_vals: [B, top_k])\n",
        "        topk_vals, topk_idx = torch.topk(logits, self.top_k, dim=-1)\n",
        "        # Áp dụng softmax lên top_vals để chuyển thành xác suất\n",
        "        gates = F.softmax(topk_vals, dim=-1)\n",
        "\n",
        "\n",
        "        B, K = gates.shape\n",
        "        hidden = None\n",
        "\n",
        "        # Lặp qua từng vị trí K trong Top-K\n",
        "        for k in range(K):\n",
        "            idx = topk_idx[:, k]\n",
        "            gate = gates[:, k].unsqueeze(-1)\n",
        "\n",
        "            # List để thu thập output từ các expert\n",
        "            chunks = []\n",
        "            for expert in range(self.num_experts):\n",
        "                # Tạo mask [Batch size, 1] - xác định xem trong số các expert thì expert nào được chọn\n",
        "                mask = (idx == expert).float().unsqueeze(-1)\n",
        "                if mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                # Tính output của expert cho toàn bộ batch\n",
        "                out_expert = self.experts[expert](x) * mask\n",
        "                # Thu thập output\n",
        "                chunks.append(out_expert)\n",
        "\n",
        "            if len(chunks) == 0:\n",
        "                continue\n",
        "\n",
        "            out_k = torch.stack(chunks, dim=0).sum(dim=0)\n",
        "            out_k = out_k * gate\n",
        "            hidden = out_k if hidden is None else hidden + out_k\n",
        "\n",
        "        hidden = self.combine(hidden)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "qdLqTBOtviia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNNFeatureExtractor**"
      ],
      "metadata": {
        "id": "fH6c6Uv_1Eqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNFeatureExtractor(nn.Module):\n",
        "    def __init__(self, feat_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.proj = nn.Linear(128, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.conv(x)\n",
        "        z = z.view(z.size(0), -1)\n",
        "        z = self.proj(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "opGd5OYj03-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Base Line Model**"
      ],
      "metadata": {
        "id": "w5W6cUor2L5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, feat_dim=128, hidden=64, num_classes=10, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.backbone = CNNFeatureExtractor(feat_dim)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feat_dim, hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        return self.head(f)"
      ],
      "metadata": {
        "id": "k64O8bEE2HzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MOE model**"
      ],
      "metadata": {
        "id": "WkmsS2v63JxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MOEModel(nn.Module):\n",
        "    def __init__(self, feat_dim=128, hidden_dim=64, num_classes=10, num_experts=8, top_k=2, dropout=0.2, noisy_std=1.0):\n",
        "        super().__init__()\n",
        "        self.backbone = CNNFeatureExtractor(feat_dim=feat_dim)\n",
        "        self.moe = SparseMOE(in_dim=feat_dim, hidden_dim=hidden_dim, num_experts=num_experts, top_k=top_k, dropout=dropout, noisy_std=noisy_std)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        h = self.moe(f)\n",
        "        return self.fc(h)"
      ],
      "metadata": {
        "id": "LPJs29vo3JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Huấn luyện và so sánh**"
      ],
      "metadata": {
        "id": "3WBM84ig4U35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    epochs: int = 5\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 0.0\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "def accuracy(pred, target):\n",
        "    return (pred.argmax(dim=1) == target).float().mean().item()\n",
        "\n",
        "def train_one_epoch(model, loader, opt, cfg: TrainConfig):\n",
        "    model.train()\n",
        "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        loss.backward()\n",
        "        if cfg.grad_clip is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        opt.step()\n",
        "        bs = x.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy(logits.detach(), y) * bs\n",
        "        total_n    += bs\n",
        "    return total_loss/total_n, total_acc/total_n\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        bs = x.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += accuracy(logits, y) * bs\n",
        "        total_n    += bs\n",
        "    return total_loss/total_n, total_acc/total_n"
      ],
      "metadata": {
        "id": "DbPyKbWK4NYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = TrainConfig(epochs=5, lr=1e-3, weight_decay=0.0, grad_clip=1.0)\n",
        "\n",
        "baseline = BaselineModel(feat_dim=128, hidden=64, num_classes=10, dropout=0.2).to(device)\n",
        "moe = MOEModel(feat_dim=128, hidden_dim=64, num_classes=10, num_experts=8, top_k=2, dropout=0.2, noisy_std=1.0).to(device)\n",
        "\n",
        "opt_base = torch.optim.Adam(baseline.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "opt_moe  = torch.optim.Adam(moe.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)"
      ],
      "metadata": {
        "id": "APC-xAvh45qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = {\"baseline\": {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [],\n",
        "                     \"train_time\": [], \"test_time\": []},\n",
        "        \"moe\": {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": [],\n",
        "               \"train_time\": [], \"test_time\": []}}\n",
        "\n",
        "print(\"== Train Baseline ==\")\n",
        "start_time_base = time.time()  # Bắt đầu đo tổng thời gian Baseline\n",
        "for epoch in range(1, cfg.epochs+1):\n",
        "    # Đo thời gian train một epoch\n",
        "    epoch_start = time.time()\n",
        "    tl, ta = train_one_epoch(baseline, train_loader, opt_base, cfg)\n",
        "    train_time = time.time() - epoch_start\n",
        "\n",
        "    # Đo thời gian evaluate một epoch\n",
        "    epoch_start = time.time()\n",
        "    vl, va = evaluate(baseline, test_loader)\n",
        "    test_time = time.time() - epoch_start\n",
        "\n",
        "    hist[\"baseline\"][\"train_loss\"].append(tl)\n",
        "    hist[\"baseline\"][\"train_acc\"].append(ta)\n",
        "    hist[\"baseline\"][\"test_loss\"].append(vl)\n",
        "    hist[\"baseline\"][\"test_acc\"].append(va)\n",
        "    hist[\"baseline\"][\"train_time\"].append(train_time)\n",
        "    hist[\"baseline\"][\"test_time\"].append(test_time)\n",
        "\n",
        "    print(f\"[Baseline][Epoch {epoch:02d}] train_loss={tl:.4f} train_acc={ta:.4f} \"\n",
        "          f\"| test_loss={vl:.4f} test_acc={va:.4f} \"\n",
        "          f\"| train_time={train_time:.2f}s test_time={test_time:.2f}s\")\n",
        "\n",
        "total_time_base = time.time() - start_time_base\n",
        "print(f\"\\nTổng thời gian huấn luyện Baseline: {total_time_base:.2f} giây\")\n",
        "\n",
        "print(\"\\n== Train MoE ==\")\n",
        "start_time_moe = time.time()  # Bắt đầu đo tổng thời gian MoE\n",
        "for epoch in range(1, cfg.epochs+1):\n",
        "    epoch_start = time.time()\n",
        "    tl, ta = train_one_epoch(moe, train_loader, opt_moe, cfg)\n",
        "    train_time = time.time() - epoch_start\n",
        "\n",
        "    epoch_start = time.time()\n",
        "    vl, va = evaluate(moe, test_loader)\n",
        "    test_time = time.time() - epoch_start\n",
        "\n",
        "    hist[\"moe\"][\"train_loss\"].append(tl)\n",
        "    hist[\"moe\"][\"train_acc\"].append(ta)\n",
        "    hist[\"moe\"][\"test_loss\"].append(vl)\n",
        "    hist[\"moe\"][\"test_acc\"].append(va)\n",
        "    hist[\"moe\"][\"train_time\"].append(train_time)\n",
        "    hist[\"moe\"][\"test_time\"].append(test_time)\n",
        "\n",
        "    print(f\"[MoE][Epoch {epoch:02d}] train_loss={tl:.4f} train_acc={ta:.4f} \"\n",
        "          f\"| test_loss={vl:.4f} test_acc={va:.4f} \"\n",
        "          f\"| train_time={train_time:.2f}s test_time={test_time:.2f}s\")\n",
        "\n",
        "total_time_moe = time.time() - start_time_moe\n",
        "print(f\"\\nTổng thời gian huấn luyện MoE: {total_time_moe:.2f} giây\")\n",
        "\n",
        "# === Tóm tắt so sánh thời gian ===\n",
        "avg_train_base = sum(hist[\"baseline\"][\"train_time\"]) / cfg.epochs\n",
        "avg_test_base  = sum(hist[\"baseline\"][\"test_time\"])  / cfg.epochs\n",
        "avg_train_moe  = sum(hist[\"moe\"][\"train_time\"])     / cfg.epochs\n",
        "avg_test_moe   = sum(hist[\"moe\"][\"test_time\"])      / cfg.epochs\n",
        "\n",
        "print(\"\\n=== SO SÁNH THỜI GIAN TRUNG BÌNH MỖI EPOCH ===\")\n",
        "print(f\"{'Model':<10} | {'Train (s)':<12} | {'Test (s)':<12} | {'Total (s)':<10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Baseline':<10} | {avg_train_base:10.2f}   | {avg_test_base:10.2f}   | {total_time_base:8.2f}\")\n",
        "print(f\"{'MoE':<10}     | {avg_train_moe:10.2f}   | {avg_test_moe:10.2f}   | {total_time_moe:8.2f}\")\n",
        "\n",
        "# Lưu lịch sử (bây giờ có thêm thời gian)\n",
        "with open(\"fashionmnist_moe_history.json\", \"w\") as f:\n",
        "    json.dump(hist, f, indent=2)\n",
        "print(\"\\nĐã lưu lịch sử (bao gồm thời gian) vào fashionmnist_moe_history.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYUxcQQa4n7H",
        "outputId": "317a0ab0-c445-4dfe-be8f-bc0fc7b6b339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Train Baseline ==\n",
            "[Baseline][Epoch 01] train_loss=1.1004 train_acc=0.5778 | test_loss=0.7354 test_acc=0.7280 | train_time=15.54s test_time=2.20s\n",
            "[Baseline][Epoch 02] train_loss=0.6654 train_acc=0.7476 | test_loss=0.5558 test_acc=0.7874 | train_time=15.26s test_time=1.89s\n",
            "[Baseline][Epoch 03] train_loss=0.5404 train_acc=0.8005 | test_loss=0.4962 test_acc=0.8191 | train_time=14.21s test_time=1.91s\n",
            "[Baseline][Epoch 04] train_loss=0.4724 train_acc=0.8296 | test_loss=0.4323 test_acc=0.8461 | train_time=14.19s test_time=1.95s\n",
            "[Baseline][Epoch 05] train_loss=0.4173 train_acc=0.8491 | test_loss=0.3982 test_acc=0.8557 | train_time=14.22s test_time=2.91s\n",
            "\n",
            "Tổng thời gian huấn luyện Baseline: 84.28 giây\n",
            "\n",
            "== Train MoE ==\n",
            "[MoE][Epoch 01] train_loss=1.2236 train_acc=0.5166 | test_loss=0.8420 test_acc=0.6691 | train_time=17.65s test_time=2.03s\n",
            "[MoE][Epoch 02] train_loss=0.7731 train_acc=0.7004 | test_loss=0.6544 test_acc=0.7528 | train_time=18.01s test_time=2.33s\n",
            "[MoE][Epoch 03] train_loss=0.6482 train_acc=0.7508 | test_loss=0.5572 test_acc=0.7850 | train_time=17.25s test_time=2.05s\n",
            "[MoE][Epoch 04] train_loss=0.5552 train_acc=0.7905 | test_loss=0.4983 test_acc=0.8133 | train_time=18.48s test_time=2.05s\n",
            "[MoE][Epoch 05] train_loss=0.4758 train_acc=0.8254 | test_loss=0.4437 test_acc=0.8351 | train_time=17.42s test_time=2.06s\n",
            "\n",
            "Tổng thời gian huấn luyện MoE: 99.33 giây\n",
            "\n",
            "=== SO SÁNH THỜI GIAN TRUNG BÌNH MỖI EPOCH ===\n",
            "Model      | Train (s)    | Test (s)     | Total (s) \n",
            "--------------------------------------------------\n",
            "Baseline   |      14.68   |       2.17   |    84.28\n",
            "MoE            |      17.76   |       2.11   |    99.33\n",
            "\n",
            "Đã lưu lịch sử (bao gồm thời gian) vào fashionmnist_moe_history.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5FQBaGS5bcj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}