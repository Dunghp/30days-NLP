{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -U transformers bitsandbytes accelerate tokenizers langchain langchainhub langchain-chroma langchain-experimental langchain-community langchain-huggingface python-dotenv pypdf streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aNxACEHPh80i",
        "outputId": "85e71fe2-63da-4938-cb34-31c7406a7e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.1.3-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting langchain-core<2.0.0,>=1.1.2 (from langchain)\n",
            "  Downloading langchain_core-1.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting chromadb<2.0.0,>=1.0.20 (from langchain-chroma)\n",
            "  Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.55)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Collecting build>=1.0.3 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (13.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.12)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (25.9.23)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.6.1)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-1.1.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading langchain_chroma-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_experimental-0.4.0-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
            "Downloading pypdf-6.4.1-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.52.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.3-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=77f88e7ac696aac4111af114730739337ee4502df3a754d72454f36bccab1586\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pypdf, pyngrok, pybase64, packaging, opentelemetry-proto, mypy-extensions, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, types-requests, requests, pydeck, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, langchainhub, dataclasses-json, opentelemetry-sdk, kubernetes, bitsandbytes, streamlit, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-huggingface, chromadb, langchain-classic, langchain-chroma, langchain-community, langchain-experimental, langchain\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.1\n",
            "    Uninstalling langchain-core-1.1.1:\n",
            "      Successfully uninstalled langchain-core-1.1.1\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.1.2\n",
            "    Uninstalling langchain-1.1.2:\n",
            "      Successfully uninstalled langchain-1.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 bitsandbytes-0.48.2 build-1.3.0 chromadb-1.3.6 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-1.1.3 langchain-chroma-1.0.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.3 langchain-experimental-0.4.0 langchain-huggingface-1.1.0 langchain-text-splitters-1.0.0 langchainhub-0.1.21 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.39.0 opentelemetry-exporter-otlp-proto-common-1.39.0 opentelemetry-exporter-otlp-proto-grpc-1.39.0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 packaging-24.2 posthog-5.4.0 pybase64-1.4.3 pydeck-0.9.1 pyngrok-7.5.0 pypdf-6.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 requests-2.32.5 streamlit-1.52.1 types-requests-2.32.4.20250913 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              },
              "id": "1f7985ffebe8440d8cde7dec88ee6512"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import torch\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from langchain_classic import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import time\n",
        "\n",
        "# Session state initialization\n",
        "if 'rag_chain' not in st.session_state:\n",
        "    st.session_state.rag_chain = None\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = False\n",
        "if 'embeddings' not in st.session_state:\n",
        "    st.session_state.embeddings = None\n",
        "if 'llm' not in st.session_state:\n",
        "    st.session_state.llm = None\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if 'pdf_processed' not in st.session_state:\n",
        "    st.session_state.pdf_processed = False\n",
        "if 'pdf_name' not in st.session_state:\n",
        "    st.session_state.pdf_name = \"\"\n",
        "\n",
        "# Functions\n",
        "@st.cache_resource\n",
        "def load_embeddings():\n",
        "    return HuggingFaceEmbeddings(model_name=\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_llm():\n",
        "    MODEL_NAME = \"lmsys/vicuna-13b-v1.5\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    model_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    return HuggingFacePipeline(pipeline=model_pipeline)\n",
        "\n",
        "def process_pdf(uploaded_file):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    loader = PyPDFLoader(tmp_file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    semantic_splitter = SemanticChunker(\n",
        "        embeddings=st.session_state.embeddings,\n",
        "        buffer_size=1,\n",
        "        breakpoint_threshold_type=\"percentile\",\n",
        "        breakpoint_threshold_amount=95,\n",
        "        min_chunk_size=500,\n",
        "        add_start_index=True\n",
        "    )\n",
        "\n",
        "    docs = semantic_splitter.split_documents(documents)\n",
        "    vector_db = Chroma.from_documents(documents=docs, embedding=st.session_state.embeddings)\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | st.session_state.llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    os.unlink(tmp_file_path)\n",
        "    return rag_chain, len(docs)\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Thêm tin nhắn vào lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history.append({\n",
        "        \"role\": role,\n",
        "        \"content\": content,\n",
        "        \"timestamp\": time.time()\n",
        "    })\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Xóa lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "def display_chat():\n",
        "    \"\"\"Hiển thị lịch sử chat\"\"\"\n",
        "    if st.session_state.chat_history:\n",
        "        for message in st.session_state.chat_history:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(message[\"content\"])\n",
        "            else:\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    st.write(message[\"content\"])\n",
        "    else:\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(\"Xin chào! Tôi là AI assistant. Hãy upload file PDF và bắt đầu đặt câu hỏi về nội dung tài liệu nhé! 😊\")\n",
        "\n",
        "# UI\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"PDF RAG Chatbot\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "    st.title(\"PDF RAG Assistant\")\n",
        "    # st.logo(\"./logo.png\", size=\"large\")\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.title(\"⚙️ Cài đặt\")\n",
        "\n",
        "        # Load models\n",
        "        if not st.session_state.models_loaded:\n",
        "            st.warning(\"⏳ Đang tải models...\")\n",
        "            with st.spinner(\"Đang tải AI models...\"):\n",
        "                st.session_state.embeddings = load_embeddings()\n",
        "                st.session_state.llm = load_llm()\n",
        "                st.session_state.models_loaded = True\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Upload PDF\n",
        "        st.subheader(\"📄 Upload tài liệu\")\n",
        "        uploaded_file = st.file_uploader(\"Chọn file PDF\", type=\"pdf\")\n",
        "\n",
        "        if uploaded_file:\n",
        "            if st.button(\"🔄 Xử lý PDF\", use_container_width=True):\n",
        "                with st.spinner(\"Đang xử lý PDF...\"):\n",
        "                    st.session_state.rag_chain, num_chunks = process_pdf(uploaded_file)\n",
        "                    st.session_state.pdf_processed = True\n",
        "                    st.session_state.pdf_name = uploaded_file.name\n",
        "                    # Reset chat history khi upload PDF mới\n",
        "                    clear_chat()\n",
        "                    add_message(\"assistant\", f\"✅ Đã xử lý thành công file **{uploaded_file.name}**!\\n\\n📊 Tài liệu được chia thành {num_chunks} phần. Bạn có thể bắt đầu đặt câu hỏi về nội dung tài liệu.\")\n",
        "                st.rerun()\n",
        "\n",
        "        # PDF status\n",
        "        if st.session_state.pdf_processed:\n",
        "            st.success(f\"📄 Đã tải: {st.session_state.pdf_name}\")\n",
        "        else:\n",
        "            st.info(\"📄 Chưa có tài liệu\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Chat controls\n",
        "        st.subheader(\"💬 Điều khiển Chat\")\n",
        "        if st.button(\"🗑️ Xóa lịch sử chat\", use_container_width=True):\n",
        "            clear_chat()\n",
        "            st.rerun()\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Instructions\n",
        "        st.subheader(\"📋 Hướng dẫn\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Cách sử dụng:**\n",
        "        1. **Upload PDF** - Chọn file và nhấn \"Xử lý PDF\"\n",
        "        2. **Đặt câu hỏi** - Nhập câu hỏi trong ô chat\n",
        "        3. **Nhận trả lời** - AI sẽ trả lời dựa trên nội dung PDF\n",
        "        \"\"\")\n",
        "\n",
        "    # Main content\n",
        "    st.markdown(\"*Trò chuyện với Chatbot để trao đổi về nội dung tài liệu PDF của bạn*\")\n",
        "\n",
        "    # Chat container\n",
        "    chat_container = st.container()\n",
        "\n",
        "    with chat_container:\n",
        "        # Display chat history\n",
        "        display_chat()\n",
        "\n",
        "    # Chat input\n",
        "    if st.session_state.models_loaded:\n",
        "        if st.session_state.pdf_processed:\n",
        "            # User input\n",
        "            user_input = st.chat_input(\"Nhập câu hỏi của bạn...\")\n",
        "\n",
        "            if user_input:\n",
        "                # Add user message\n",
        "                add_message(\"user\", user_input)\n",
        "\n",
        "                # Display user message immediately\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(user_input)\n",
        "\n",
        "                # Generate response\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    with st.spinner(\"Đang suy nghĩ...\"):\n",
        "                        try:\n",
        "                            output = st.session_state.rag_chain.invoke(user_input)\n",
        "                            # Clean up the response\n",
        "                            if 'Answer:' in output:\n",
        "                                answer = output.split('Answer:')[1].strip()\n",
        "                            else:\n",
        "                                answer = output.strip()\n",
        "\n",
        "                            # Display response\n",
        "                            st.write(answer)\n",
        "\n",
        "                            # Add assistant message to history\n",
        "                            add_message(\"assistant\", answer)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            error_msg = f\"Xin lỗi, đã có lỗi xảy ra: {str(e)}\"\n",
        "                            st.error(error_msg)\n",
        "                            add_message(\"assistant\", error_msg)\n",
        "        else:\n",
        "            st.info(\"🔄 Vui lòng upload và xử lý file PDF trước khi bắt đầu chat!\")\n",
        "            st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "    else:\n",
        "        st.info(\"⏳ Đang tải AI models, vui lòng đợi...\")\n",
        "        st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ror4fjJwTs0S",
        "outputId": "e01fd427-2aa3-4f42-ad87-50591128c556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken thay bang token cua ban"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_xMxt3xjH-8",
        "outputId": "b1c7c4b8-543e-40e3-95c9-63ffc22362ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect('8053')\n",
        "print(f\"Please click on the text below {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI2pLAWSfyoe",
        "outputId": "644e20aa-45fa-47e1-d854-e26b5b9460fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please click on the text below NgrokTunnel: \"https://4b6b1bfae908.ngrok-free.app\" -> \"http://localhost:8053\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run --server.port 8053 app.py > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgO87l1qT5LN",
        "outputId": "8a51115a-b119-4f1b-b0be-2e1ae848e068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-10 09:24:29.133584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765358669.154602    1613 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765358669.161153    1613 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765358669.177558    1613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765358669.177582    1613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765358669.177586    1613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765358669.177591    1613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-10 09:24:29.183152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "modules.json: 100% 229/229 [00:00<00:00, 1.83MB/s]\n",
            "config_sentence_transformers.json: 100% 123/123 [00:00<00:00, 1.15MB/s]\n",
            "README.md: 6.46kB [00:00, 25.2MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 532kB/s]\n",
            "config.json: 100% 777/777 [00:00<00:00, 7.85MB/s]\n",
            "model.safetensors: 100% 540M/540M [00:03<00:00, 146MB/s]\n",
            "tokenizer_config.json: 1.17kB [00:00, 7.06MB/s]\n",
            "vocab.txt: 895kB [00:00, 35.8MB/s]\n",
            "bpe.codes: 1.14MB [00:00, 125MB/s]\n",
            "added_tokens.json: 100% 22.0/22.0 [00:00<00:00, 253kB/s]\n",
            "special_tokens_map.json: 100% 167/167 [00:00<00:00, 1.82MB/s]\n",
            "config.json: 100% 270/270 [00:00<00:00, 2.53MB/s]\n",
            "config.json: 100% 638/638 [00:00<00:00, 5.75MB/s]\n",
            "pytorch_model.bin.index.json: 33.4kB [00:00, 126MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00003.bin:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   0% 0.00/6.18G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json: 35.1kB [00:00, 105MB/s]\n",
            "\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   0% 737k/6.18G [00:00<2:05:16, 822kB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   0% 945k/9.95G [00:01<3:13:16, 858kB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 1.01M/9.90G [00:01<3:22:16, 816kB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 68.0M/9.95G [00:03<07:27, 22.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 202M/9.95G [00:04<02:42, 59.9MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 336M/9.95G [00:06<02:25, 66.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   0% 2.39M/6.18G [00:06<4:41:10, 366kB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 403M/9.95G [00:06<02:00, 78.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   1% 68.0M/9.90G [00:07<16:03, 10.2MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 470M/9.95G [00:07<01:53, 83.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   2% 136M/6.18G [00:07<03:56, 25.5MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   4% 271M/6.18G [00:09<02:40, 36.7MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 537M/9.95G [00:10<03:36, 43.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   2% 202M/9.90G [00:13<10:21, 15.6MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 672M/9.95G [00:14<03:53, 39.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   3% 269M/9.90G [00:14<07:17, 22.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 739M/9.95G [00:14<03:14, 47.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:   8% 472M/6.18G [00:15<02:30, 38.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 806M/9.95G [00:15<02:48, 54.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  11% 673M/6.18G [00:15<01:30, 60.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 873M/9.95G [00:18<03:37, 41.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   3% 336M/9.90G [00:18<08:08, 19.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  12% 740M/6.18G [00:19<02:02, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   5% 537M/9.90G [00:19<03:29, 44.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  14% 874M/6.18G [00:19<01:29, 59.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   6% 604M/9.90G [00:20<03:05, 50.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 940M/9.95G [00:20<03:47, 39.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  15% 941M/6.18G [00:20<01:19, 65.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   7% 672M/9.90G [00:20<02:48, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  16% 1.01G/6.18G [00:21<01:12, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   7% 739M/9.90G [00:21<02:24, 63.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   9% 873M/9.90G [00:22<01:58, 75.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.01G/9.95G [00:22<04:28, 33.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.01G/9.90G [00:24<01:44, 85.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.14G/6.18G [00:24<01:27, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.08G/9.90G [00:24<01:37, 90.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.21G/9.90G [00:25<01:18, 111MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.14G/9.95G [00:25<03:44, 39.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.21G/6.18G [00:25<01:30, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.34G/9.90G [00:26<01:08, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.21G/9.95G [00:26<03:06, 46.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.28G/6.18G [00:28<01:52, 43.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.28G/9.95G [00:28<03:39, 39.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.34G/6.18G [00:28<01:35, 50.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.41G/9.95G [00:29<02:23, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.41G/9.90G [00:29<02:28, 57.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.54G/9.90G [00:30<01:52, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.61G/9.95G [00:31<01:45, 78.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.41G/6.18G [00:31<01:54, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.61G/9.90G [00:31<01:50, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.68G/9.95G [00:31<01:47, 77.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.54G/6.18G [00:32<01:14, 62.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.75G/9.95G [00:34<02:22, 57.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.68G/9.90G [00:35<03:07, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.81G/9.90G [00:36<02:11, 61.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.88G/9.95G [00:36<02:17, 58.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.88G/9.90G [00:40<03:40, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 2.01G/9.95G [00:41<03:02, 43.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.68G/6.18G [00:41<02:40, 28.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  20% 2.01G/9.90G [00:41<02:34, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.75G/6.18G [00:44<02:54, 25.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.08G/9.90G [00:45<03:29, 37.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.08G/9.95G [00:45<04:07, 31.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.81G/6.18G [00:46<02:36, 28.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.21G/9.90G [00:46<02:43, 47.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.15G/9.95G [00:47<03:52, 33.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.88G/6.18G [00:47<02:09, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.28G/9.90G [00:47<02:22, 53.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.01G/6.18G [00:48<01:27, 47.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.21G/9.95G [00:51<04:46, 27.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.15G/6.18G [00:51<01:24, 48.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.35G/9.90G [00:51<03:33, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.21G/6.18G [00:53<01:41, 39.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.28G/9.95G [00:55<05:37, 22.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.42G/9.90G [00:57<05:19, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.49G/9.90G [01:01<05:49, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.48G/9.95G [01:04<05:39, 22.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.35G/6.18G [01:05<03:01, 21.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.55G/9.90G [01:05<06:13, 19.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.62G/9.95G [01:11<05:42, 21.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.62G/9.90G [01:11<07:40, 15.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.68G/9.95G [01:11<04:45, 25.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.69G/9.90G [01:15<07:19, 16.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.88G/9.95G [01:15<03:28, 33.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.42G/6.18G [01:16<04:32, 13.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 3.02G/9.95G [01:19<03:32, 32.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.75G/9.90G [01:20<07:40, 15.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.48G/6.18G [01:20<04:25, 13.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.89G/9.90G [01:21<04:26, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.96G/9.90G [01:21<03:38, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.16G/9.90G [01:22<01:55, 58.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.09G/9.95G [01:22<03:43, 30.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.62G/6.18G [01:23<02:59, 19.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.15G/9.95G [01:24<03:22, 33.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.68G/6.18G [01:24<02:30, 23.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.22G/9.95G [01:25<03:01, 37.1MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.88G/6.18G [01:25<01:17, 42.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.29G/9.95G [01:26<02:36, 42.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.02G/6.18G [01:26<01:00, 51.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.15G/6.18G [01:30<01:07, 45.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.29G/9.90G [01:30<03:26, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.36G/9.95G [01:30<03:58, 27.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.29G/6.18G [01:35<01:21, 35.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.36G/9.90G [01:35<04:24, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.36G/6.18G [01:36<01:11, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.49G/9.90G [01:36<03:05, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.49G/9.95G [01:37<04:26, 24.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.56G/9.95G [01:39<04:12, 25.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.42G/6.18G [01:39<01:21, 33.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.62G/9.95G [01:40<03:33, 29.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  56% 3.49G/6.18G [01:44<01:44, 25.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.56G/9.90G [01:46<05:20, 19.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.56G/6.18G [01:46<01:37, 27.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.62G/9.90G [01:47<04:27, 23.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.76G/6.18G [01:47<00:49, 49.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.69G/9.90G [01:50<04:30, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.76G/9.95G [01:50<05:06, 20.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.83G/6.18G [01:50<00:58, 40.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.83G/9.95G [01:51<04:07, 24.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  64% 3.96G/6.18G [01:51<00:40, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.76G/9.90G [01:51<03:49, 26.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.89G/9.95G [01:51<03:25, 29.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.96G/9.95G [01:56<04:22, 22.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.09G/6.18G [01:56<00:54, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.83G/9.90G [01:57<05:10, 19.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 4.03G/9.95G [01:59<04:08, 23.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.89G/9.90G [01:59<04:43, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.09G/9.95G [02:00<03:30, 27.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.23G/6.18G [02:00<00:51, 37.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.30G/6.18G [02:01<00:43, 43.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.23G/9.95G [02:01<02:09, 44.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.03G/9.90G [02:04<04:11, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.36G/6.18G [02:05<00:56, 32.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.43G/6.18G [02:06<00:47, 37.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.16G/9.90G [02:06<03:03, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.30G/9.95G [02:07<03:40, 25.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.30G/9.90G [02:07<02:10, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.56G/6.18G [02:10<00:48, 33.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.36G/9.95G [02:10<03:52, 24.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.43G/9.90G [02:14<02:58, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.37G/9.95G [02:15<06:05, 15.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.50G/9.90G [02:16<02:45, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.57G/9.95G [02:17<02:49, 31.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.63G/6.18G [02:17<01:10, 22.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.56G/9.90G [02:17<02:32, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.64G/9.95G [02:20<03:12, 27.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.70G/6.18G [02:20<01:09, 21.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.63G/9.90G [02:21<03:06, 28.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.76G/6.18G [02:25<01:11, 19.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.70G/9.90G [02:25<03:38, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.70G/9.95G [02:26<04:00, 21.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.84G/9.90G [02:26<02:07, 39.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.84G/6.18G [02:26<00:54, 24.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.77G/9.95G [02:26<03:11, 27.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.90G/9.90G [02:31<03:03, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.84G/9.95G [02:32<04:19, 19.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.97G/9.90G [02:33<02:51, 28.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.91G/6.18G [02:34<01:20, 15.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.97G/9.95G [02:34<02:56, 28.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.04G/6.18G [02:35<00:43, 26.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.04G/9.90G [02:35<02:58, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.18G/6.18G [02:36<00:25, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.24G/6.18G [02:41<00:34, 27.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.04G/9.95G [02:41<04:07, 19.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.31G/6.18G [02:41<00:25, 34.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.37G/6.18G [02:41<00:18, 44.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.44G/6.18G [02:42<00:14, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.51G/6.18G [02:43<00:11, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.17G/9.90G [02:43<03:27, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.24G/9.90G [02:43<02:43, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.11G/9.95G [02:44<03:51, 20.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.58G/6.18G [02:44<00:09, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.64G/6.18G [02:44<00:07, 69.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.24G/9.95G [02:44<02:21, 33.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.31G/9.95G [02:45<01:56, 40.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.31G/9.90G [02:45<02:40, 28.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.71G/6.18G [02:49<00:15, 31.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.37G/9.90G [02:49<03:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.78G/6.18G [02:50<00:10, 39.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.44G/9.95G [02:50<02:22, 31.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.44G/9.90G [02:51<02:39, 27.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.84G/6.18G [02:51<00:07, 43.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.51G/9.95G [02:51<01:59, 37.1MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  96% 5.91G/6.18G [02:52<00:05, 52.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.57G/9.95G [02:52<01:39, 43.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.64G/9.95G [02:55<02:10, 33.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.51G/9.90G [02:55<03:19, 22.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.71G/9.95G [02:56<01:40, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.64G/9.90G [02:56<01:55, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  97% 5.98G/6.18G [02:56<00:06, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.04G/6.18G [02:59<00:04, 27.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.11G/6.18G [03:00<00:01, 36.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.78G/9.95G [03:06<03:59, 17.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.91G/9.95G [03:06<02:18, 29.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.04G/9.95G [03:07<01:30, 43.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.71G/9.90G [03:07<04:14, 16.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.11G/9.95G [03:08<01:19, 48.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.84G/9.90G [03:08<02:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.91G/9.90G [03:08<02:03, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00003-of-00003.bin: 100% 6.18G/6.18G [03:09<00:00, 32.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.18G/9.95G [03:09<01:13, 51.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.25G/9.95G [03:09<00:59, 62.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.38G/9.95G [03:10<00:41, 86.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.98G/9.90G [03:10<01:55, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.51G/9.95G [03:10<00:28, 123MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.58G/9.95G [03:11<00:27, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.04G/9.90G [03:11<01:47, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.65G/9.95G [03:12<00:33, 99.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.18G/9.90G [03:12<01:08, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.71G/9.95G [03:12<00:31, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.78G/9.95G [03:13<00:32, 98.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.25G/9.90G [03:16<01:36, 37.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.85G/9.95G [03:16<00:57, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.91G/9.95G [03:17<00:51, 58.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.38G/9.90G [03:17<01:10, 50.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.98G/9.95G [03:18<00:53, 55.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.45G/9.90G [03:20<01:22, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.58G/9.90G [03:20<00:55, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.05G/9.95G [03:23<01:34, 30.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.65G/9.90G [03:25<01:27, 37.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.12G/9.95G [03:25<01:34, 30.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.72G/9.90G [03:25<01:13, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.78G/9.90G [03:26<01:02, 50.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.25G/9.95G [03:26<01:01, 43.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.85G/9.90G [03:27<00:57, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.32G/9.95G [03:28<00:56, 46.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  71% 6.98G/9.90G [03:30<00:55, 52.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.05G/9.90G [03:30<00:47, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.38G/9.95G [03:31<01:11, 35.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.19G/9.90G [03:32<00:38, 70.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.25G/9.90G [03:33<00:36, 73.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.45G/9.95G [03:33<01:12, 34.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.52G/9.95G [03:33<00:54, 44.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.32G/9.90G [03:33<00:35, 73.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.45G/9.90G [03:38<00:56, 43.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.58G/9.95G [03:38<01:28, 26.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.58G/9.90G [03:44<01:12, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.65G/9.95G [03:45<02:02, 18.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.79G/9.95G [03:45<01:08, 31.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.92G/9.95G [03:46<00:41, 48.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.05G/9.95G [03:46<00:28, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.65G/9.90G [03:46<01:10, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.12G/9.95G [03:47<00:24, 75.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.72G/9.90G [03:47<00:57, 37.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.85G/9.90G [03:48<00:36, 56.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.19G/9.95G [03:48<00:25, 69.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  81% 7.99G/9.90G [03:48<00:24, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.26G/9.95G [03:49<00:23, 71.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.28G/9.95G [03:50<00:27, 60.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.34G/9.95G [03:50<00:21, 74.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.05G/9.90G [03:50<00:28, 64.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.19G/9.90G [03:50<00:18, 93.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.25G/9.90G [03:53<00:25, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.32G/9.90G [03:53<00:19, 81.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.41G/9.95G [03:53<00:37, 40.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.39G/9.90G [03:54<00:18, 80.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.48G/9.95G [03:54<00:27, 52.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.55G/9.95G [03:54<00:19, 71.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.44G/9.90G [03:54<00:19, 76.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.61G/9.95G [03:55<00:17, 76.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.50G/9.90G [03:59<00:39, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.68G/9.95G [03:59<00:34, 36.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.57G/9.90G [03:59<00:29, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.75G/9.95G [03:59<00:25, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.64G/9.90G [04:00<00:21, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.81G/9.95G [04:00<00:19, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.88G/9.95G [04:00<00:14, 74.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.95G/9.95G [04:00<00:10, 93.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.70G/9.90G [04:01<00:20, 58.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.02G/9.95G [04:01<00:09, 96.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.77G/9.90G [04:01<00:16, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.08G/9.95G [04:03<00:12, 69.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.84G/9.90G [04:03<00:17, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.90G/9.90G [04:03<00:12, 79.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.15G/9.95G [04:08<00:28, 27.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  91% 8.97G/9.90G [04:09<00:33, 27.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.04G/9.90G [04:09<00:22, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.22G/9.95G [04:13<00:33, 21.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.11G/9.90G [04:13<00:28, 27.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.28G/9.95G [04:13<00:22, 29.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.17G/9.90G [04:14<00:20, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.35G/9.95G [04:14<00:15, 38.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.24G/9.90G [04:14<00:14, 46.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.31G/9.90G [04:14<00:09, 60.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.42G/9.95G [04:15<00:11, 46.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.48G/9.95G [04:15<00:07, 60.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.37G/9.90G [04:15<00:07, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.44G/9.90G [04:15<00:05, 87.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.51G/9.90G [04:16<00:04, 92.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.55G/9.95G [04:16<00:06, 59.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.61G/9.95G [04:19<00:07, 44.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.58G/9.90G [04:18<00:06, 54.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.64G/9.90G [04:19<00:04, 65.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.68G/9.95G [04:19<00:04, 54.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.70G/9.90G [04:19<00:02, 83.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.75G/9.95G [04:20<00:03, 66.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.77G/9.90G [04:20<00:01, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.81G/9.95G [04:23<00:03, 36.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.84G/9.90G [04:24<00:01, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.88G/9.95G [04:24<00:01, 45.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.90G/9.90G [04:24<00:00, 37.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.95G/9.95G [04:29<00:00, 36.9MB/s]\n",
            "Fetching 3 files: 100% 3/3 [04:29<00:00, 89.85s/it] \n",
            "Loading checkpoint shards: 100% 3/3 [02:10<00:00, 43.57s/it]\n",
            "generation_config.json: 100% 192/192 [00:00<00:00, 1.59MB/s]\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "tokenizer_config.json: 100% 749/749 [00:00<00:00, 6.28MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.20MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 3.00MB/s]\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-12-10T09:33:29+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8053-0b5c232c-8fad-431f-8a1b-129ba105ac7f acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-12-10T09:33:29+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8053-0b5c232c-8fad-431f-8a1b-129ba105ac7f err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6wD3udfV8Rp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}